{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets,transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import time\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from subprocess import check_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('fashion-mnist_train.csv')\n",
    "data_test = pd.read_csv('fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministric = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter\n",
    "batch_size = 50\n",
    "learning_rate = 0.005\n",
    "num_epochs = 10\n",
    "\n",
    "#Architecture\n",
    "img_size=28\n",
    "channel=1\n",
    "num_classes = 10\n",
    "\n",
    "#device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self,data,transform=None):\n",
    "        self.fashion_mnist = list(data.values)\n",
    "        self.transform = transform\n",
    "        label, img = [], []\n",
    "        for one_line in self.fashion_mnist:\n",
    "            label.append(one_line[0])\n",
    "            img.append(one_line[1:])\n",
    "        self.label = np.asarray(label)\n",
    "        self.img = np.asarray(img).reshape(-1, img_size, img_size, channel).astype('float32')\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        label, img = self.label[item], self.img[item]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return label, img\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytransform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_data = MyDataset(data_train, transform=mytransform)\n",
    "test_data = MyDataset(data_test, transform=mytransform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mymodel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(mymodel, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Linear(7 * 7 * 32, num_classes)\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model = mymodel(num_classes).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        for batch_id, (label,image) in enumerate(train_loader):\n",
    "            label, image = label.to(device), image.to(device)\n",
    "            output = model(image)\n",
    "            loss = criterion(output, label)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch_id % 1000 == 0:\n",
    "                print('Loss :{:.4f} Epoch[{}/{}]'.format(loss.item(), epoch, num_epochs))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for label, image in test_loader:\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "            outputs = model(image)\n",
    "            predicted = torch.argmax(outputs,dim=1)\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "        print('Test Accuracy : {} %'.format(100*correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss :2.3756 Epoch[1/10]\n",
      "Loss :0.3763 Epoch[1/10]\n",
      "Loss :0.3629 Epoch[2/10]\n",
      "Loss :0.3455 Epoch[2/10]\n",
      "Loss :0.3140 Epoch[3/10]\n",
      "Loss :0.2988 Epoch[3/10]\n",
      "Loss :0.2950 Epoch[4/10]\n",
      "Loss :0.2575 Epoch[4/10]\n",
      "Loss :0.2479 Epoch[5/10]\n",
      "Loss :0.2193 Epoch[5/10]\n",
      "Loss :0.2270 Epoch[6/10]\n",
      "Loss :0.2052 Epoch[6/10]\n",
      "Loss :0.2406 Epoch[7/10]\n",
      "Loss :0.1708 Epoch[7/10]\n",
      "Loss :0.2137 Epoch[8/10]\n",
      "Loss :0.1647 Epoch[8/10]\n",
      "Loss :0.1948 Epoch[9/10]\n",
      "Loss :0.0918 Epoch[9/10]\n",
      "Loss :0.1746 Epoch[10/10]\n",
      "Loss :0.1359 Epoch[10/10]\n",
      "Test Accuracy : 90.65 %\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    model = train()\n",
    "    test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/tinydman/fashin-mnist-with-pytorch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
